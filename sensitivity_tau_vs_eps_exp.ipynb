{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure plotting\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "matplotlib.rcParams['figure.figsize'] = (10, 4)\n",
    "matplotlib.rcParams['text.usetex'] = True\n",
    "matplotlib.rcParams['text.latex.preamble'] = r'\\usepackage{amsmath}'\n",
    "matplotlib.rcParams['font.size'] = 16\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import GPy\n",
    "import numpy as np\n",
    "RANDOM_SEED=123\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from utils.model import GPyModel\n",
    "\n",
    "from utils.utils import discretized_normal_distribution, sample_index_from_p\n",
    "from utils.utils import w_x_t, kappa_x_w, MMD, worst_context_distribution_DRO\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handcrafted function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For visualization purposes,\n",
    "# the function surface we plot is denser than the function surface we optimize.\n",
    "# We load both of them individually\n",
    "load_path = os.path.join(\"functions\", \"custom.npy\")\n",
    "load_path_plot = os.path.join(\"functions\", \"custom_plot.npy\")\n",
    "\n",
    "# Domain for action and context\n",
    "X_lim = [-3.5, 3.5]\n",
    "C_lim = [-12, 12]\n",
    "\n",
    "# Action and context cardinalities\n",
    "N_x = 8\n",
    "N_c = 50\n",
    "\n",
    "X = np.linspace(X_lim[0], X_lim[1], N_x)  # Vector of X values\n",
    "C = np.linspace(C_lim[0], C_lim[1], N_c)  # Vector of C values\n",
    "\n",
    "# Generation of matrix M for MMD\n",
    "C_kern = GPy.kern.RBF(input_dim=1, lengthscale=5)\n",
    "M = C_kern.K(C.reshape(N_c, 1))\n",
    "\n",
    "# Generation of all context, action pairs (input domain).\n",
    "x, c = np.meshgrid(X, C)\n",
    "CX_pairs = np.concatenate([x.reshape(-1, 1), c.reshape(-1, 1)], axis=1)  # All C, X pairs\n",
    "\n",
    "# Objective function and its flattened version\n",
    "func_mat_CX = np.load(load_path).reshape(N_c, N_x)\n",
    "func_vals = func_mat_CX.reshape(-1, 1)\n",
    "\n",
    "\n",
    "# ----- These are only for plotting of objective function\n",
    "# Since we are not plotting the surface alongside the regrets, we're not using these.\n",
    "\n",
    "N_x_p = 50\n",
    "\n",
    "func_mat_CX_plot = np.load(load_path_plot).reshape(N_c, N_x_p)\n",
    "\n",
    "# -----\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "ax[0].imshow(func_mat_CX_plot, interpolation='bicubic')\n",
    "ax[1].imshow(M, interpolation='bicubic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_w_true_and_ref():\n",
    "    \"\"\"Generates and returns w_true and w_ref according to the experiment setup.\"\"\"\n",
    "    \n",
    "    w_ref = discretized_normal_distribution(C, 2, (1)**2)\n",
    "    w_true = discretized_normal_distribution(C, 0, (5)**2)\n",
    "\n",
    "    return w_true, w_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_observation(flat_indices, noise_std=0):\n",
    "    \"\"\"Given a list of (action, context) indices, returns the noisy observations.\n",
    "    Note that, instead of 2D indexing, flattened indices are used.\"\"\"\n",
    "    Y_sample = func_vals[flat_indices].reshape(-1, 1)\n",
    "    Y_sample_n = Y_sample + np.random.randn(*Y_sample.shape) * noise_std\n",
    "    \n",
    "    return Y_sample_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BO_loop_DRO(model, distributions, contexts, epsilon_coef, beta, T):\n",
    "    CX_t_indices = []\n",
    "    for t in range(T):\n",
    "        # True and reference distributions\n",
    "        w_true, w_ref = distributions[t]\n",
    "\n",
    "        # The variable epsilon here is the radius of the ambiguity set of DRBO\n",
    "        # true distance multiplied with a coefficient, e.g. 1/3\n",
    "        epsilon_t = MMD(M, w_true, w_ref) * epsilon_coef\n",
    "\n",
    "        # Modelling\n",
    "        mu, var = model.predict(CX_pairs)\n",
    "        CX_pair_UCB = mu + beta*np.sqrt(var)\n",
    "        CX_mat_UCB = CX_pair_UCB.reshape(N_c, N_x)\n",
    "\n",
    "        # For each action, calculate worst expected reward in the ambiguity set\n",
    "        worst_expected_reward_x = np.zeros(N_x)\n",
    "        for x_ind in range(N_x):\n",
    "            UCB_x = CX_mat_UCB[:, x_ind]\n",
    "            worst_w_x = worst_context_distribution_DRO(M, w_ref, UCB_x, epsilon_t)\n",
    "            worst_expected_reward_x[x_ind] = np.dot(worst_w_x.T, UCB_x)\n",
    "        \n",
    "        # Choose maximum of these worst expected rewards.\n",
    "        chosen_action_index = np.argmax(worst_expected_reward_x)\n",
    "        # Context is observed from precomputed context vector.\n",
    "        observed_context_index = contexts[t]\n",
    "        # Add selected action and observed context indices to the array to be returned\n",
    "        CX_t_indices.append([observed_context_index, chosen_action_index])\n",
    "\n",
    "        # Add new sample to model and update the model\n",
    "        cx_flattened_index = observed_context_index*N_x + chosen_action_index\n",
    "        CX_sample = CX_pairs[[cx_flattened_index]]\n",
    "        Y_sample_n = get_observation([cx_flattened_index], noise_std=model.noise_std)\n",
    "        model.add_sample(CX_sample, Y_sample_n)\n",
    "        model.update()\n",
    "\n",
    "        print(\"Chosen action point:\", CX_sample[0][0])\n",
    "\n",
    "    return CX_t_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BO_loop_RS(model, distributions, contexts, beta, T, taus):\n",
    "    # Aspiration is currently not used.\n",
    "\n",
    "    kappas = np.zeros(T)\n",
    "    CX_t_indices = []\n",
    "    for t in range(T):\n",
    "        w_true, w_ref = distributions[t]\n",
    "        w_true = w_true.reshape(N_c, 1)\n",
    "        w_ref = w_ref.reshape(N_c, 1)\n",
    "        \n",
    "        tau = taus[t]\n",
    "        \n",
    "        # Modelling\n",
    "        mu, var = model.predict(CX_pairs)\n",
    "        CX_pair_UCB = mu + beta*np.sqrt(var)\n",
    "        CX_mat_UCB = CX_pair_UCB.reshape(N_c, N_x)\n",
    "\n",
    "        # For each action, calculate kappa_hat_tau,t and kappa_tau,t\n",
    "        list_kappa_x = np.zeros(N_x)\n",
    "        list_kappa_hat_x = np.zeros(N_x)\n",
    "        for x_ind in range(N_x):\n",
    "            ucb_x = CX_mat_UCB[:, x_ind].reshape(-1, 1)\n",
    "            w_bar_x_t = w_x_t(M, w_ref, ucb_x, tau)\n",
    "            kappa_hat_x = kappa_x_w(M, w_ref, w_bar_x_t, ucb_x, tau, clip=False)\n",
    "            list_kappa_hat_x[x_ind] = kappa_hat_x\n",
    "            \n",
    "            f_x = func_mat_CX[:, x_ind].reshape(-1, 1)\n",
    "            w_dbar_x_t = w_x_t(M, w_ref, f_x, tau)\n",
    "            kappa_x = kappa_x_w(M, w_ref, w_dbar_x_t, f_x, tau, clip=False)\n",
    "            list_kappa_x[x_ind] = kappa_x\n",
    "\n",
    "        # Choose action with minimum kappa_hat.\n",
    "        chosen_action_index = np.argmin(list_kappa_hat_x)\n",
    "        # Context is observed from precomputed context vector.\n",
    "        observed_context_index = contexts[t]\n",
    "        # Add selected action and observed context indices to the array to be returned\n",
    "        CX_t_indices.append([observed_context_index, chosen_action_index])\n",
    "\n",
    "        # Add new sample to model and update the model\n",
    "        cx_flattened_index = observed_context_index*N_x + chosen_action_index\n",
    "        CX_sample = CX_pairs[[cx_flattened_index]]\n",
    "        Y_sample_n = get_observation([cx_flattened_index], noise_std=model.noise_std)\n",
    "        model.add_sample(CX_sample, Y_sample_n)\n",
    "        model.update()\n",
    "\n",
    "        print(\"Chosen action point:\", CX_sample[0][0], \" - Kappa:\", np.min(list_kappa_hat_x))\n",
    "\n",
    "        # Save minimum kappa for regret calculation.\n",
    "        min_kappa = np.min(list_kappa_x)\n",
    "        kappas[t] = min_kappa\n",
    "\n",
    "    return CX_t_indices, kappas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loop over tau's and save all experiments\n",
    "\n",
    "\n",
    "# Model simulation parameters: simulation count, timestep count and dro epsilons\n",
    "\n",
    "# Reset the randomness\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "sim_count = 10\n",
    "timestep_count = 200 + 1  # +1 for undersampled plotting (last tick in the plot)\n",
    "initial_sample_cnt = 3\n",
    "\n",
    "# Different ball radius coefficients for DRO\n",
    "RS_aspirations = [0.9]  # Currently not used\n",
    "\n",
    "# Modelling parameters\n",
    "input_dim = 2\n",
    "output_dim = 1\n",
    "noise_std = 0.02\n",
    "noise_var = np.square(noise_std)\n",
    "beta = 2\n",
    "\n",
    "ker = GPy.kern.RBF(input_dim=input_dim, ARD=True)\n",
    "ker.lengthscale = (0.2, 5)\n",
    "\n",
    "\n",
    "simulation_name = datetime.now().strftime(\"%m_%d_%Y-%H_%M_%S\")\n",
    "simulation_folder = os.path.join(\n",
    "    \"results\",\n",
    "    f\"synth_TAU_sim{sim_count}_ts{timestep_count}-std-{noise_std:.2f}-{simulation_name}\"\n",
    ")\n",
    "os.makedirs(simulation_folder, exist_ok=False)\n",
    "\n",
    "\n",
    "# tau in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.]\n",
    "fixed_tau_list = np.linspace(0.1, 1, 10).round(2)\n",
    "for fixed_tau in fixed_tau_list:\n",
    "    # Reset the randomness\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    \n",
    "    # Model simulations\n",
    "\n",
    "    # Initial samples for each simulation\n",
    "    initial_samples_sims = np.empty((sim_count, initial_sample_cnt, input_dim+output_dim))\n",
    "    # Time dependent true and reference distributions for each simulation\n",
    "    distributions_w_true_and_ref_sims = np.empty((sim_count, timestep_count, 2, N_c))\n",
    "    # Chosen (action, context) pairs for each simulation of RS\n",
    "    indices_RS_sims_asp = np.empty((len(RS_aspirations), sim_count, timestep_count, 2))\n",
    "    # Kappa prime values for each simulation and timestep, we calculate these in RS loop\n",
    "    kappas_sims_asp = np.empty((len(RS_aspirations), sim_count, timestep_count))\n",
    "    # Tau values for each simulation and timestep, since we use a fixed tau this is constant\n",
    "    taus_sims_asp = np.empty((len(RS_aspirations), sim_count, timestep_count))\n",
    "    if fixed_tau is not None:\n",
    "        taus_sims_asp[:] = fixed_tau\n",
    "\n",
    "    for sim in range(sim_count):\n",
    "        print(f\"\\n\\n------------------------ SIMULATION NUMBER: {sim:02d} ------------------------\\n\\n\")\n",
    "\n",
    "        # Randomly select initial samples\n",
    "        cx_flattened_initial_indices = np.random.randint(\n",
    "            low=0, high=N_c*N_x, size=initial_sample_cnt,\n",
    "        )\n",
    "        initial_CX = CX_pairs[cx_flattened_initial_indices]\n",
    "        initial_Y_n = get_observation(cx_flattened_initial_indices)\n",
    "        initial_samples_sims[sim] = np.hstack((initial_CX, initial_Y_n))\n",
    "\n",
    "\n",
    "        # Create context distributions and sample context at each timestep for all algorithms.\n",
    "        # All algorithms run with same distributions and contexts for each simulation.\n",
    "        context_counts_wrt_true = np.zeros((N_c, 1))\n",
    "        sim_contexts = np.empty(timestep_count, dtype=int)\n",
    "        for t in range(timestep_count):\n",
    "            w_true, w_ref = create_w_true_and_ref()\n",
    "            distributions_w_true_and_ref_sims[sim, t, 0] = w_true.flatten()\n",
    "            distributions_w_true_and_ref_sims[sim, t, 1] = w_ref.flatten()\n",
    "            ts_context = sample_index_from_p(w_true)\n",
    "            \n",
    "            sim_contexts[t] = ts_context\n",
    "\n",
    "            if fixed_tau is None:\n",
    "                pass\n",
    "\n",
    "        # RS simulation\n",
    "        for asp_i, asp in enumerate(RS_aspirations):\n",
    "            print(f\"\\nRS with aspiration={asp:.3f}\\n\")\n",
    "            model_RS = GPyModel(input_dim, output_dim, noise_var, ker=ker)\n",
    "\n",
    "            model_RS.add_sample(initial_CX, initial_Y_n)\n",
    "            model_RS.update()\n",
    "            \n",
    "            chosen_indices_RS, kappas = BO_loop_RS(\n",
    "                model_RS, distributions=distributions_w_true_and_ref_sims[sim],\n",
    "                contexts=sim_contexts, beta=beta, T=timestep_count, taus=taus_sims_asp[asp_i, sim]\n",
    "            )\n",
    "            indices_RS_sims_asp[asp_i][sim] = chosen_indices_RS\n",
    "            kappas_sims_asp[asp_i][sim] = kappas\n",
    "\n",
    "\n",
    "    # Write simulation results\n",
    "    sub_simulation_folder = os.path.join(\n",
    "        simulation_folder,\n",
    "        f\"tau_{fixed_tau}\"\n",
    "    )\n",
    "    os.makedirs(sub_simulation_folder, exist_ok=False)\n",
    "\n",
    "    np.save(os.path.join(sub_simulation_folder, \"initial_samples_sims\"), initial_samples_sims)\n",
    "    np.save(os.path.join(sub_simulation_folder, \"distributions_w_true_and_ref_sims\"), distributions_w_true_and_ref_sims)\n",
    "    np.save(os.path.join(sub_simulation_folder, \"indices_RS_sims_asp\"), indices_RS_sims_asp)\n",
    "    np.save(os.path.join(sub_simulation_folder, \"kappas_sims_asp\"), kappas_sims_asp)\n",
    "    np.save(os.path.join(sub_simulation_folder, \"taus_sims_asp\"), taus_sims_asp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loop over tau's and save all experiments\n",
    "\n",
    "\n",
    "# Model simulation parameters: simulation count, timestep count and dro epsilons\n",
    "\n",
    "# Reset the randomness\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "sim_count = 10\n",
    "timestep_count = 200 + 1  # +1 for undersampled plotting (last label to show)\n",
    "initial_sample_cnt = 3\n",
    "\n",
    "# Different ball radius coefficients for DRO\n",
    "DRO_epsilons = np.logspace(-1, 1, 11, base=10)\n",
    "RS_aspirations = [0.9]  # Currently not used\n",
    "\n",
    "# Time independent tau value\n",
    "fixed_tau = 0.6\n",
    "assert fixed_tau is None or (fixed_tau is not None and len(RS_aspirations)==1)\n",
    "\n",
    "# Modelling parameters\n",
    "input_dim = 2\n",
    "output_dim = 1\n",
    "noise_std = 0.02\n",
    "noise_var = np.square(noise_std)\n",
    "beta = 2\n",
    "\n",
    "ker = GPy.kern.RBF(input_dim=input_dim, ARD=True)\n",
    "ker.lengthscale = (0.2, 5)\n",
    "\n",
    "\n",
    "simulation_folder = os.path.join(\n",
    "    \"results\",\n",
    "    f\"synth_TAU_sim{sim_count}_ts{timestep_count}-std-{noise_std:.2f}-{simulation_name}\"\n",
    ")\n",
    "# os.makedirs(simulation_folder, exist_ok=False)\n",
    "\n",
    "\n",
    "# Reset the randomness\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Model simulations\n",
    "\n",
    "# Initial samples for each simulation\n",
    "initial_samples_sims = np.empty((sim_count, initial_sample_cnt, input_dim+output_dim))\n",
    "# Time dependent true and reference distributions for each simulation\n",
    "distributions_w_true_and_ref_sims = np.empty((sim_count, timestep_count, 2, N_c))\n",
    "# Chosen (action, context) pairs for each simulation of each DRO epsilon\n",
    "indices_DRO_sims_eps = np.empty((len(DRO_epsilons), sim_count, timestep_count, 2))\n",
    "# Tau values for each simulation and timestep, since we use a fixed tau this is constant\n",
    "taus_sims_asp = np.empty((len(RS_aspirations), sim_count, timestep_count))\n",
    "if fixed_tau is not None:\n",
    "    taus_sims_asp[:] = fixed_tau\n",
    "\n",
    "for sim in range(sim_count):\n",
    "    print(f\"\\n\\n------------------------ SIMULATION NUMBER: {sim:02d} ------------------------\\n\\n\")\n",
    "\n",
    "    # Randomly select initial samples\n",
    "    cx_flattened_initial_indices = np.random.randint(\n",
    "        low=0, high=N_c*N_x, size=initial_sample_cnt,\n",
    "    )\n",
    "    initial_CX = CX_pairs[cx_flattened_initial_indices]\n",
    "    initial_Y_n = get_observation(cx_flattened_initial_indices)\n",
    "    initial_samples_sims[sim] = np.hstack((initial_CX, initial_Y_n))\n",
    "\n",
    "\n",
    "    # Create context distributions and sample context at each timestep for all algorithms.\n",
    "    # All algorithms run with same distributions and contexts for each simulation.\n",
    "    context_counts_wrt_true = np.zeros((N_c, 1))\n",
    "    sim_contexts = np.empty(timestep_count, dtype=int)\n",
    "    for t in range(timestep_count):\n",
    "        w_true, w_ref = create_w_true_and_ref()\n",
    "        distributions_w_true_and_ref_sims[sim, t, 0] = w_true.flatten()\n",
    "        distributions_w_true_and_ref_sims[sim, t, 1] = w_ref.flatten()\n",
    "        ts_context = sample_index_from_p(w_true)\n",
    "        \n",
    "        sim_contexts[t] = ts_context\n",
    "\n",
    "        if fixed_tau is None:\n",
    "            pass\n",
    "        \n",
    "    # DRO simulations with different epsilons\n",
    "    for eps_i, eps in enumerate(DRO_epsilons):\n",
    "        print(f\"\\nDRO with eps={eps:.3f}\\n\")\n",
    "        model_DRO = GPyModel(input_dim, output_dim, noise_var, ker=ker)\n",
    "\n",
    "        model_DRO.add_sample(initial_CX, initial_Y_n)\n",
    "        model_DRO.update()\n",
    "        \n",
    "        chosen_indices_DRO = BO_loop_DRO(\n",
    "            model_DRO, distributions=distributions_w_true_and_ref_sims[sim], contexts=sim_contexts,\n",
    "            epsilon_coef=eps, beta=beta, T=timestep_count\n",
    "        )\n",
    "        indices_DRO_sims_eps[eps_i][sim] = chosen_indices_DRO\n",
    "\n",
    "\n",
    "# Write simulation results\n",
    "sub_simulation_folder = os.path.join(\n",
    "    simulation_folder,\n",
    "    f\"eps\"\n",
    ")\n",
    "os.makedirs(sub_simulation_folder, exist_ok=False)\n",
    "\n",
    "np.save(os.path.join(sub_simulation_folder, \"initial_samples_sims\"), initial_samples_sims)\n",
    "np.save(os.path.join(sub_simulation_folder, \"distributions_w_true_and_ref_sims\"), distributions_w_true_and_ref_sims)\n",
    "np.save(os.path.join(sub_simulation_folder, \"indices_DRO_sims_eps\"), indices_DRO_sims_eps)\n",
    "np.save(os.path.join(sub_simulation_folder, \"taus_sims_asp\"), taus_sims_asp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot palettes\n",
    "colors = sns.color_palette(\"dark\")\n",
    "greens = sns.color_palette(\"BuGn\", 10)\n",
    "blues = sns.color_palette(\"PuBu\", 10)\n",
    "reds = sns.color_palette(\"YlOrRd\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read simulation results\n",
    "\n",
    "\n",
    "# [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]\n",
    "fixed_tau_list = np.linspace(0.1, 1, 10).round(2)\n",
    "\n",
    "cum_rewards = np.empty((1, len(fixed_tau_list)))\n",
    "for tau_i, fixed_tau in enumerate(fixed_tau_list):\n",
    "    distributions_w_true_and_ref_sims = np.load(\n",
    "        os.path.join(simulation_folder, f\"tau_{fixed_tau}\", \"distributions_w_true_and_ref_sims.npy\")\n",
    "    )\n",
    "    indices_RS_sims_asp = np.load(\n",
    "        os.path.join(simulation_folder, f\"tau_{fixed_tau}\", \"indices_RS_sims_asp.npy\")).astype(int\n",
    "    )\n",
    "\n",
    "    # Expected rewards of simulations and timesteps w.r.t. f\n",
    "    expected_reward_true_sims_ts = distributions_w_true_and_ref_sims[:, :, 0, :] @ func_mat_CX\n",
    "\n",
    "    # MMD distances of simulations and timesteps\n",
    "    mmd_sims_ts = np.empty((sim_count, timestep_count))\n",
    "    for sim_i in range(sim_count):\n",
    "        for ts_i in range(timestep_count):\n",
    "            mmd_sims_ts[sim_i, ts_i] = MMD(M, *distributions_w_true_and_ref_sims[sim_i, ts_i])\n",
    "\n",
    "    # Calculate rewards\n",
    "\n",
    "    # RS rewards\n",
    "    true_rewards_of_actions_RS_asp = np.empty((len(RS_aspirations), sim_count, timestep_count))\n",
    "    for a_i in range(len(RS_aspirations)):\n",
    "        true_rewards_of_actions_RS_asp[a_i] = expected_reward_true_sims_ts[\n",
    "            np.arange(sim_count)[:, None],\n",
    "            np.arange(timestep_count),\n",
    "            indices_RS_sims_asp[a_i, :, :, 1].astype(int)\n",
    "        ]\n",
    "\n",
    "    cum_rewards[0][tau_i] = true_rewards_of_actions_RS_asp[0].mean(axis=0).mean()\n",
    "\n",
    "DRO_epsilons = np.logspace(-1, 1, 11, base=10)\n",
    "cum_rewards_dro = np.empty((1, len(DRO_epsilons)))\n",
    "for eps_i, eps in enumerate(DRO_epsilons):\n",
    "    distributions_w_true_and_ref_sims = np.load(\n",
    "        os.path.join(simulation_folder, f\"eps\", \"distributions_w_true_and_ref_sims.npy\")\n",
    "    )\n",
    "    indices_DRO_sims_eps = np.load(\n",
    "        os.path.join(simulation_folder, f\"eps\", \"indices_DRO_sims_eps.npy\")).astype(int\n",
    "    )\n",
    "\n",
    "    # Expected rewards of simulations and timesteps w.r.t. f\n",
    "    expected_reward_true_sims_ts = distributions_w_true_and_ref_sims[:, :, 0, :] @ func_mat_CX\n",
    "\n",
    "    # MMD distances of simulations and timesteps\n",
    "    mmd_sims_ts = np.empty((sim_count, timestep_count))\n",
    "    for sim_i in range(sim_count):\n",
    "        for ts_i in range(timestep_count):\n",
    "            mmd_sims_ts[sim_i, ts_i] = MMD(M, *distributions_w_true_and_ref_sims[sim_i, ts_i])\n",
    "\n",
    "    # Calculate rewards\n",
    "\n",
    "    # DRO rewards\n",
    "    true_rewards_of_actions_DRO_eps = np.empty((len(DRO_epsilons), sim_count, timestep_count))\n",
    "    for e_i in range(len(DRO_epsilons)):\n",
    "        true_rewards_of_actions_DRO_eps[e_i] = expected_reward_true_sims_ts[\n",
    "            np.arange(sim_count)[:, None],\n",
    "            np.arange(timestep_count),\n",
    "            indices_DRO_sims_eps[e_i, :, :, 1].astype(int)\n",
    "        ]\n",
    "\n",
    "    cum_rewards_dro[0][eps_i] = true_rewards_of_actions_DRO_eps[eps_i].mean(axis=0).mean()\n",
    "\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (6, 4)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "\n",
    "# Label, color, linestyle\n",
    "lcls = [\n",
    "    (\"RoBOS\", reds[-1], \"-\", \".\"),\n",
    "    (\"DRBO\", blues[-2], \":\", \".\"),\n",
    "]\n",
    "\n",
    "ax.set_xlabel(r\"$\\tau$\")\n",
    "ax.set_ylabel(r\"Avg. Reward\")\n",
    "\n",
    "label, color, linestyle, marker = lcls[0]\n",
    "ax.plot(\n",
    "    fixed_tau_list, cum_rewards[0], label=label, c=color, linestyle=linestyle, marker=marker\n",
    ")\n",
    "label, color, linestyle, marker = lcls[1]\n",
    "ax.plot(\n",
    "    np.linspace(0.1, 1, 11).round(2), cum_rewards_dro[0], label=label, c=color, linestyle=linestyle, marker=marker\n",
    ")\n",
    "\n",
    "ax.set_xticks(np.linspace(0.1, 1, 10).round(2))\n",
    "ax.set_xticklabels(np.linspace(0.1, 1, 10).round(2))\n",
    "\n",
    "secax0 = ax.secondary_xaxis(\"top\")\n",
    "secax0.set_xlabel(r\"$\\times\\epsilon$\")\n",
    "secax0.set_xticks(np.linspace(0.1, 1, 11).round(2))\n",
    "secax0.set_xticklabels(DRO_epsilons.round(2), fontsize=10)\n",
    "\n",
    "\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(Path(simulation_folder), Path(simulation_folder).name + '_taus.pdf'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ef69ea586ce447b115e27b53430e939eed52b263ffde8f64417a998839050d39"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
